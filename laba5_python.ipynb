{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "https://github.com/d7anSeR/lab2_aisdc/blob/main/laba5_python.ipynb",
      "authorship_tag": "ABX9TyPcP1FPdAeoQ/oiATQ1+mH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d7anSeR/lab5_python/blob/main/laba5_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "NfTGy3lvT6Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rjCvywdxkiHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "INBP-aXKDKEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "KGsmIbv8c0Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_columns(name_class_good: str, name_class_bad: str, df: pd.DataFrame) -> None:\n",
        "    '''create columns of DataFrame'''\n",
        "    df['review'] = \"\"\n",
        "    i = 0\n",
        "    for file_dataset in os.listdir(\"dataset\"):\n",
        "        path_p = os.path.join(\"dataset\", file_dataset)\n",
        "        class_name = os.listdir(path_p)\n",
        "        for elem in class_name:\n",
        "            name = os.path.join(path_p, elem)\n",
        "            f = open(name, mode='rt', encoding='utf-8')\n",
        "            data = f.read()\n",
        "            df.loc[[i], 'review'] = data\n",
        "            f.close()\n",
        "            i += 1"
      ],
      "metadata": {
        "id": "UZB6QgQnc5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_class_good = \"good\"\n",
        "name_class_bad = \"bad\"\n",
        "tmp = []\n",
        "data = pd.read_csv('annotation', encoding='utf-16', delimiter=';',\n",
        "                 names=['absolut_path', 'otnos_path', 'class_name'])\n",
        "tmp.append(data)\n",
        "df = pd.concat(tmp)\n",
        "df = df.drop(['otnos_path'], axis=1)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "EA29ba8ac9dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
        "tokenize = lambda x: word_tokenize(x)\n",
        "ps = PorterStemmer()\n",
        "stem = lambda w: [ ps.stem(x) for x in w ]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
      ],
      "metadata": {
        "id": "pU_9GNw1dA90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_columns(name_class_good, name_class_bad, df)\n",
        "df"
      ],
      "metadata": {
        "id": "uPEeisCIdEkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Processing : [=', end='')\n",
        "df['review'] = df['review'].apply(remove_non_alphabets)\n",
        "print('=', end='')\n",
        "df\n",
        "# df['review'] = df['review'].apply(tokenize) # [ word_tokenize(row) for row in data['email']]\n",
        "# print('=', end='')\n",
        "df['review'] = df['review'].apply(stem)\n",
        "print('=', end='')\n",
        "# df['review'] = df['review'].apply(leammtizer)\n",
        "# print('=', end='')\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join(x))\n",
        "print('] : Completed', end='')\n",
        "df"
      ],
      "metadata": {
        "id": "nWTC_5RpdHCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}