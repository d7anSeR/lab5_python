{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "https://github.com/d7anSeR/lab5_python/blob/main/laba5_python.ipynb",
      "authorship_tag": "ABX9TyPktXzuA0ogphUC6IaZYy97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d7anSeR/lab5_python/blob/main/laba5_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "NfTGy3lvT6Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "Sjk34aThvAZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "import string\n",
        "\n",
        "import pymorphy2\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "rjCvywdxkiHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "INBP-aXKDKEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "KGsmIbv8c0Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_columns(name_class_good: str, name_class_bad: str, df: pd.DataFrame) -> None:\n",
        "    '''create columns of DataFrame'''\n",
        "    df['review'] = \"\"\n",
        "    i = 0\n",
        "    for file_dataset in os.listdir(\"dataset\"):\n",
        "        path_p = os.path.join(\"dataset\", file_dataset)\n",
        "        class_name = os.listdir(path_p)\n",
        "        for elem in class_name:\n",
        "            name = os.path.join(path_p, elem)\n",
        "            f = open(name, mode='rt', encoding='utf-8')\n",
        "            data = f.read()\n",
        "            df.loc[[i], 'review'] = data\n",
        "            f.close()\n",
        "            i += 1"
      ],
      "metadata": {
        "id": "UZB6QgQnc5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(text) -> list:\n",
        "    '''lemmatization of the text'''\n",
        "    new_list = []\n",
        "    tt = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "    elem = text.translate(tt)\n",
        "    if elem is not None:\n",
        "        list_words = elem.split()\n",
        "    for word in list_words:\n",
        "        p = morph.parse(word)[0]\n",
        "        new_list.append(p.normal_form)\n",
        "    return new_list"
      ],
      "metadata": {
        "id": "SpF5iY-QscE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_class_good = \"good\"\n",
        "name_class_bad = \"bad\"\n",
        "tmp = []\n",
        "data = pd.read_csv('annotation', encoding='utf-16', delimiter=';',\n",
        "                 names=['absolut_path', 'otnos_path', 'class_name'])\n",
        "tmp.append(data)\n",
        "df = pd.concat(tmp)\n",
        "df = df.drop(['otnos_path'], axis=1)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "EA29ba8ac9dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMqB17rHrnHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
        "tokenize = lambda x: word_tokenize(x)\n",
        "ps = PorterStemmer()\n",
        "stem = lambda w: [ ps.stem(x) for x in w ]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
      ],
      "metadata": {
        "id": "pU_9GNw1dA90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_columns(name_class_good, name_class_bad, df)\n",
        "df"
      ],
      "metadata": {
        "id": "uPEeisCIdEkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Processing : [=', end='')\n",
        "df['review'] = df['review'].apply(lemmatize) # [ word_tokenize(row) for row in data['email']]\n",
        "print('=', end='')\n",
        "df['review'] = df['review'].apply(stem)\n"
      ],
      "metadata": {
        "id": "4hPK0hwcrznn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('=', end='')\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join(x))\n",
        "print('] : Completed', end='')"
      ],
      "metadata": {
        "id": "tF99SU90y91D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "wfcL6ErVzHwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "cv = CountVectorizer(max_features=max_words, stop_words='english')\n",
        "sparse_matrix = cv.fit_transform(df['review']).toarray()"
      ],
      "metadata": {
        "id": "VPU7R63wz1iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix.shape"
      ],
      "metadata": {
        "id": "uOCGMxKy0Sr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(df['class_name']))"
      ],
      "metadata": {
        "id": "1B39JhNu0bBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear1 = nn.Linear(10000, 100)\n",
        "        self.linear2 = nn.Linear(100, 10)\n",
        "        self.linear3 = nn.Linear(10, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cUIYFVZ74mfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "EO5ScW0Z4p_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)"
      ],
      "metadata": {
        "id": "fYyf-pNT4rLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = Variable(torch.from_numpy(x_train)).float()\n",
        "y_train = Variable(torch.from_numpy(y_train)).long()"
      ],
      "metadata": {
        "id": "oDq-44Jp9m9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}